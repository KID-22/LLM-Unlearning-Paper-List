# LLM-Unlearning-Survey
【202402】Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models [[PDF](https://arxiv.org/pdf/2402.05813.pdf)] 

【202401】Unlearning Reveals the Influential Training Data of Language Models [[PDF](https://arxiv.org/pdf/2401.15241.pdf)]

【202401】TOFU: A Task of Fictitious Unlearning for LLMs [[PDF](https://arxiv.org/pdf/2401.06121.pdf)]

【202312】Learning and Forgetting Unsafe Examples in Large Language Models [[PDF](https://arxiv.org/pdf/2312.12736v1.pdf)]

【NeurIPS2023 Workshop】FAIRSISA: ENSEMBLE POST-PROCESSING TO IMPROVE FAIRNESS OF UNLEARNING IN LLMS [[PDF](https://arxiv.org/pdf/2312.07420v1.pdf)]

【202311】Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges [[PDF](https://arxiv.org/ftp/arxiv/papers/2311/2311.15766.pdf)] 

【202311】Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models [[PDF](https://arxiv.org/pdf/2311.08011v1.pdf)] 

【202311】Making Harmful Behaviors Unlearnable for Large Language Models  [[PDF](https://arxiv.org/pdf/2311.02105v1.pdf)] 

【EMNLP2023】Unlearn What You Want to Forget: Efficient Unlearning for LLMs [[PDF](https://arxiv.org/pdf/2310.20150v1.pdf)] 

【202310】Large Language Model Unlearning

【202310】In-Context Unlearning: Language Models as Few Shot Unlearners

【202310】Who’s Harry Potter? Approximate Unlearning in LLMs

【202309】Neural Code Completion Tools Can Memorize Hard-coded Credentials

【202308】Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operatio

【202307】Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal Data

【202307】What can we learn from Data Leakage and Unlearning for Law?

【202305】Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions

【202302】Knowledge Unlearning for Mitigating Privacy Risks in Language Models

【ACL2023】Unlearning Bias in Language Models by Partitioning Gradients

【202212】Privacy Adhering Machine Un-learning in NLP

【NeurIPS2022】Quark: Controllable Text Generation with Reinforced Unlearning

【ACL2022】Knowledge Neurons in Pretrained Transformers

【CCS2020】Analyzing Information Leakage of Updates to Natural Language Models
